version: '3.5'

services:
    broker:
        command: confluent broker
        container_name: broker
        depends_on:
            - zookeeper
        dns: 10.1.3.1
        dns_search:
            - ubuntu.home
            - home
        environment:
            DEBUG_TRACE: ${DEBUG_TRACE:-0}
            KAFKA_ADVERTISED_HOST_NAME: ${HOST_IP:?}
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${HOST_IP:?}:9092
#            KAFKA_ADVERTISED_LISTENERS: SASL_PLAINTEXT://${HOST_IP:?}:9092
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
            KAFKA_BOOTSTRAP_SERVERS: $KAFKA_BOOTSTRAP_SERVERS
            KAFKA_BROKER_ID: ${KAFKA_ID:?}
            KAFKA_COMPRESSION_TYPE: gzip
            KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: 'true'
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            KAFKA_HEAP_OPTS: "-Xmx6G -Xms6G"
            KAFKA_JMX_OPTS: "-Djava.rmi.server.hostname=${HOST_IP:?} -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.rmi.port=9091 -Dcom.sun.management.jmxremote.port=9091 -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dzookeeper.sasl.client=ZkClient"
            KAFKA_JMX_PORT: 9091
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
#            KAFKA_LISTENERS: SASL_PLAINTEXT://0.0.0.0:9092
            KAFKA_NUM_PARTITIONS: 1
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
            KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_ZOOKEEPER_CONNECT: ${ZOOKEEPER_HOSTS:?}
            ZOOKEEPER_TIMEOUT: 6000
        hostname: broker.s4.home
        image: ${DOCKER_REGISTRY:-ubuntu-s2.home:5000/}${CONTAINER_OS:-alpine}/confluent/${CONFLUENT_VERSION:-5.4.0}:${CONTAINER_TAG:-fca1e371005b398ef1de41f43fc8b2316881a00434c0d8bbc35f08182bc7ef8d}
        logging:
            driver: json-file
            options:
                max-file: "3"
                max-size: "10m"
        links:
           - zookeeper
        networks:
            - kafka-net
        ports:
            - "9091:9091"
            - "9092:9092"
        restart: unless-stopped
        volumes:
            - ./broker/data:/usr/local/confluent/data
            - ./broker/logs:/usr/local/confluent/logs
            - ./broker/log:/var/log

#
# docker.io/obsidiandynamics/kafdrop
#
    kafdrop:
        container_name: kafdrop
        dns: 10.1.3.1
        dns_search:
            - ubuntu.home
            - home
        environment:
            JVM_OPTS: "-Xms32M -Xmx64M"
#            JMX_PORT:
            KAFKA_BROKERCONNECT: $KAFKA_BOOTSTRAP_SERVERS
#            KAFKA_PROPERTIES: $(cat kafka.properties | base64)
#            KAFKA_TRUSTSTORE: $(cat kafka.truststore.jks | base64)  # optional
#            KAFKA_KEYSTORE: $(cat kafka.keystore.jks | base64)      # optional
        hostname: kafdrop.s4.home
        image: ${DOCKER_REGISTRY:-ubuntu-s2.home:5000/}thirdparty/kafdrop:${KAFDROP_VERSION:-3.23.0}
        logging:
            driver: json-file
            options:
                max-file: "3"
                max-size: "10m" 
        networks:
            - kafka-net
        ports:
            - "8998:9000"
        restart: unless-stopped
        volumes:
            - ./kafdrop/log:/var/log


# https://docs.kafka-eagle.org/2.env-and-install/2.installing
    kafkaeagle:
        container_name: kafka-eagle
        dns: 10.1.3.1
        dns_search:
            - ubuntu.home
            - home
        environment:
            KE_HOME: /opt/kafka-eagle
            KAFKA_ZOOKEEPER_HOSTS: s3.ubuntu.home:2181,s4.ubuntu.home:2181
#            DB_HOST: 10.1.3.6
#            DB_USER: bobb
#            DB_PASSWORD: 123Oleary
        hostname: kafkaeagle.s4.home
        image: ${DOCKER_REGISTRY:-ubuntu-s2.home:5000/}${CONTAINER_OS:-alpine}/kafka-eagle/${KAFKA_EAGLE_VERSION:-1.4.3}:${CONTAINER_TAG:-fd2bbca83ec68b357b27777b7232864bbe79f17abbd1d9dd27ebdf80441ecaf2}
        networks:
            - kafka-net
        ports:
            - "8048:8048"
            - "8996:8080"
        restart: unless-stopped
        volumes:
            - ./kafkaeagle/conf:/opt/kafka-eagle/conf
            - ./kafkaeagle/log:/opt/kafka-eagle/logs


# https://hub.docker.com/r/tchiotludo/kafkahq
# https://github.com/tchiotludo/kafkahq
    kafkahq:
        container_name: kafkahq
        environment:
            KAFKAHQ_CONFIGURATION: |
                kafkahq:
                    connections:
                        docker-kafka-server:
                            properties:
                                bootstrap.servers: "s3.ubuntu.home:9092,s4.ubuntu.home:9092"
        hostname: kafkahq.s4.home
        image: ${DOCKER_REGISTRY:-ubuntu-s2.home:5000/}thirdparty/kafkahq:${KAFKAHQ_VERSION:-0.12.0}
        logging:
            driver: json-file
            options:
                max-file: "3"
                max-size: "10m" 
        networks:
            - kafka-net
        ports:
            - "8997:8080"
        volumes:
            - ./kafkahq/log:/var/log


    zookeeper:
        command: confluent zookeeper
        container_name: zookeeper
        dns: 10.1.3.1
        dns_search:
            - ubuntu.home
            - home
        environment:
            DEBUG_TRACE: ${DEBUG_TRACE:-0}
            ZOOKEEPER_SERVER_ID: ${KAFKA_ID:?}
            ZOOKEEPER_CLIENTPORT: 2181
            ZOOKEEPER_TICKTIME: 2000
            ZOOKEEPER_INITLIMIT: 10
            ZOOKEEPER_SYNCLIMIT: 5
            ZOOKEEPER_SERVER.1: 10.1.3.6:2888:3888
            ZOOKEEPER_SERVER.2: 0.0.0.0:2888:3888
            ZOOKEEPER_SERVER.3: 10.1.3.14:2888:3888
        hostname: zookeeper.s4.home
        image: ${DOCKER_REGISTRY:-ubuntu-s2.home:5000/}${CONTAINER_OS:-alpine}/confluent/${CONFLUENT_VERSION:-5.4.0}:${CONTAINER_TAG:-fca1e371005b398ef1de41f43fc8b2316881a00434c0d8bbc35f08182bc7ef8d}
        logging:
            driver: json-file
            options:
                max-size: "10m"
                max-file: "3"
        networks:
            - kafka-net
        ports:
            - "2181:2181"
            - "2888:2888"
            - "3888:3888"
        restart: unless-stopped
        volumes:
            - ./zookeeper/data:/usr/local/confluent/data
            - ./zookeeper/logs:/usr/local/confluent/logs 
            - ./zookeeper/log:/var/log


#
# docker.io/elkozmon/zoonavigator
#
    zoonavigator:
        container_name: zoonavigator
        dns: 10.1.3.1
        dns_search:
            - ubuntu.home
            - home
        environment:
            DEBUG_TRACE: ${DEBUG_TRACE:-0}
            HTTP_PORT: 9000
        hostname: zoonavigator.s4.home
        image: ${DOCKER_REGISTRY:-ubuntu-s2.home:5000/}thirdparty/zoonavigator:${ZOONAVIGATOR_VERSION:-0.8.0}
        logging:
            driver: json-file
            options:
                max-size: "10m"
                max-file: "3"
#        network_mode: "host"
        networks:
            - kafka-net
        ports:
            - "8999:9000"
        restart: unless-stopped
        volumes:
            - ./zoonavigator/log:/var/log

 
networks:
   kafka-net:
       name: kafka-container-net


secrets:
   kafka.secret:
     file: .secrets/secrets/kafkamgr.secret
   kafka_manager.pwd:
     file: .secrets/secrets/bobb.pwd
